{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994daa5c",
   "metadata": {},
   "source": [
    "Here we find the extrinsics of our camera calibration w.r.t the RV calibration board using the RV calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43203d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/universal/Downloads/dev.sk_robot_rgbd_data/src')\n",
    "from skrgbd.calibration.calibrations.small_scale_sphere import Calibration\n",
    "from skrgbd.calibration.camera_models.central_generic import CentralGeneric\n",
    "from skrgbd.calibration.camera_models.rv_camera_model import fit_camera_model, RVCameraModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb61dd",
   "metadata": {},
   "source": [
    "## Fit the transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576f2fb",
   "metadata": {},
   "source": [
    "Scan something with texture, for instance, our calibration board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dir = Path(\n",
    "    '/home/universal/Downloads/dev.sk_robot_rgbd_data/stl_shared_folder/scans/test_calib_board_folder'\n",
    ")\n",
    "scan_id = 0\n",
    "rv_camera_model = RVCameraModel(f'{scan_dir}/scan_res_{scan_id:04}/Raw/imparb01.txt')\n",
    "\n",
    "calib_dir = Calibration.calib_dir\n",
    "our_camera_model = CentralGeneric(f'{calib_dir}/stl_right_intrinsics.yaml',\n",
    "                                  f'{calib_dir}/stl_right_inverse_grid.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970683e",
   "metadata": {},
   "source": [
    "Fit the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c579a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation, translation, residuals = fit_camera_model(\n",
    "    our_camera_model, rv_camera_model,\n",
    "    samples_n=1_000_000,\n",
    "    depth_range=(.1, 2),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8054c12",
   "metadata": {},
   "source": [
    "Check that the residuals are small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = 4\n",
    "plt.figure(figsize=(4 * _, _))\n",
    "plt.hist(residuals, 1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e725e3",
   "metadata": {},
   "source": [
    "Save the transform to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53574880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_calib_to_stl_right = _ = torch.zeros(4, 4)\n",
    "_[3, 3] = 1\n",
    "_[:3, :3] = rotation\n",
    "_[:3, 3] = translation\n",
    "torch.save(rv_calib_to_stl_right, f'{calib_dir}/rv_calib_to_stl_right.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7e7ef",
   "metadata": {},
   "source": [
    "## Check the transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4ddaa",
   "metadata": {},
   "source": [
    "In RV ScanCenter there are several different coordinate spaces:\n",
    "* camera space,\n",
    "* the space of the calibration board,\n",
    "* the \"mesh space\",\n",
    "* the world space.\n",
    "\n",
    "\n",
    "* The `Raw/impara01.txt` and `Raw/imparb01.txt` define the transform between the camera space and the space of the calibration board.\n",
    "* The transform from the space of the calibration board to the \"mesh space\" is defined in `vertex_matrix.txt`.\n",
    "* The transform from the \"mesh space\" to the world space is defined in `Raw/M_scenemesh.bin`\n",
    "\n",
    "When you export in `ply` format, the scan is saved in the \"mesh space\",\n",
    "and when you export in any other format (in fact, checked only for `obj`), the scan is saved in the world space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = f'{scan_dir}/test_calib_board/Mesh_{scan_id:04}/Mesh_{scan_id:04}.obj'\n",
    "scenemesh = f'{scan_dir}/scan_res_{scan_id:04}/Raw/M_scenemesh.bin'\n",
    "vertex_matrix =  f'{scan_dir}/scan_res_{scan_id:04}/vertex_matrix.txt'\n",
    "texture_left = f'{scan_dir}/scan_res_{scan_id:04}/Debug/Pictures/cama_maxwhite_00_0000.bmp'\n",
    "texture_right = f'{scan_dir}/scan_res_{scan_id:04}/Debug/Pictures/camb_maxwhite_00_0000.bmp'\n",
    "\n",
    "scan = o3d.io.read_triangle_mesh(scan)\n",
    "\n",
    "texture_left = Image.open(texture_left)\n",
    "texture_left = np.asarray(texture_left)\n",
    "h, w = texture_left.shape\n",
    "\n",
    "texture_right = Image.open(texture_right)\n",
    "texture_right = np.asarray(texture_right)\n",
    "\n",
    "scenemesh = np.fromfile(scenemesh, dtype=np.float32).reshape(4, 4)\n",
    "scenemesh = torch.from_numpy(scenemesh).double()\n",
    "mesh_to_world = scenemesh\n",
    "\n",
    "vertex_matrix = np.loadtxt(vertex_matrix)\n",
    "vertex_matrix = torch.from_numpy(vertex_matrix).double()\n",
    "board_to_mesh = vertex_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_calib_to_stl_right = torch.load(f'{calib_dir}/rv_calib_to_stl_right.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29312e4",
   "metadata": {},
   "source": [
    "### Check in 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16623553",
   "metadata": {},
   "source": [
    "Transfer texture coordinates from the triangle vertices to the mesh vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a654635",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = np.asarray(scan.triangles)\n",
    "triangle_uvs = np.asarray(scan.triangle_uvs)\n",
    "\n",
    "triangles = torch.from_numpy(triangles).long()\n",
    "triangle_uvs = torch.from_numpy(triangle_uvs)\n",
    "\n",
    "vertex_uvs = torch.full([len(scan.vertices), 2], -1, dtype=torch.double)\n",
    "vertex_uvs.scatter_(0, triangles.view(-1).unsqueeze(1).expand_as(triangle_uvs), triangle_uvs)\n",
    "\n",
    "assert (vertex_uvs[triangles.ravel()] == triangle_uvs).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c32054",
   "metadata": {},
   "source": [
    "Sample colors from the texture, i.e photo from left STL camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = vertex_uvs * 2 - 1\n",
    "grid[:, 1] *= -1\n",
    "\n",
    "colors = torch.nn.functional.grid_sample(\n",
    "    torch.from_numpy(texture_left).double().div(255).unsqueeze(0).unsqueeze(1),\n",
    "    grid.unsqueeze(0).unsqueeze(1),\n",
    "    mode='bilinear'\n",
    ").squeeze(2).squeeze(0)\n",
    "colors = colors.T.clamp(0, 1).expand(-1, 3).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd69d50",
   "metadata": {},
   "source": [
    "Transform scan vertices to our camera space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_verts = np.asarray(scan.vertices)\n",
    "scan_verts = torch.from_numpy(scan_verts.T).contiguous()\n",
    "\n",
    "mm_to_meters = torch.zeros(4, 4)\n",
    "mm_to_meters[3, 3] = 1\n",
    "mm_to_meters[0, 0] = mm_to_meters[1, 1] = mm_to_meters[2, 2] = 1 / 1000\n",
    "\n",
    "world_to_our_cam = rv_calib_to_stl_right @ mm_to_meters @ board_to_mesh.inverse() @ mesh_to_world.inverse()\n",
    "\n",
    "scan_verts = world_to_our_cam[:3, :3] @ scan_verts + world_to_our_cam[:3, 3:4]\n",
    "\n",
    "scan_verts = torch.nn.functional.normalize(scan_verts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425befdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = o3d.geometry.PointCloud()\n",
    "pc.points = o3d.utility.Vector3dVector(scan_verts.T.contiguous().numpy())\n",
    "pc.colors = o3d.utility.Vector3dVector(colors.contiguous().numpy())\n",
    "o3d.io.write_point_cloud('/tmp/verts.ply', pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6ff87",
   "metadata": {},
   "source": [
    "Unproject pixels from our camera, i.e the right STL camera, to the camera space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, u = torch.meshgrid(torch.arange(0, h, dtype=torch.double), torch.arange(0, w, dtype=torch.double))\n",
    "uv = torch.stack([u.ravel() + .5, v.ravel() + .5]).contiguous()\n",
    "\n",
    "scan_verts_from_texture = our_camera_model.unproject(uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5eb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_colors = torch.from_numpy(texture_right).double().div(255).ravel().unsqueeze(1).expand(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58912c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = o3d.geometry.PointCloud()\n",
    "\n",
    "_ = scan_verts_from_texture.isfinite().all(0)\n",
    "pc.points = o3d.utility.Vector3dVector(scan_verts_from_texture.T[_].contiguous().numpy())\n",
    "pc.colors = o3d.utility.Vector3dVector(texture_colors[_].contiguous().numpy())\n",
    "pc.remove_non_finite_points()\n",
    "o3d.io.write_point_cloud('/tmp/verts_from_texture.ply', pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33043a9f",
   "metadata": {},
   "source": [
    "### Check in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11563324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/universal/Downloads/dev.sk_robot_rgbd_data/debug/depth_map_reprojection_example/dev.mvs4df/src')\n",
    "from mvs4df.modules.pointcloud_rendering.render_points import render_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64502ef",
   "metadata": {},
   "source": [
    "Project scan vertices in our camera space to the image space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "our_camera_model = our_camera_model.to(device)\n",
    "uv = our_camera_model.project_fine(scan_verts.to(device)).cpu()\n",
    "our_camera_model = our_camera_model.to('cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e9df7",
   "metadata": {},
   "source": [
    "Check the quality of the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = our_camera_model.unproject(uv)\n",
    "_ = (_ - torch.nn.functional.normalize(scan_verts, dim=0)).norm(dim=0)\n",
    "plt.hist(_.numpy(), 1000);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b98458",
   "metadata": {},
   "source": [
    "Render the projected points into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = colors.T.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = our_camera_model.size_wh\n",
    "\n",
    "render = render_points(\n",
    "    colors.unsqueeze(0),\n",
    "    scan_verts[2].unsqueeze(0),\n",
    "    uv.unsqueeze(1),\n",
    "    (h, w),\n",
    "    point_radius=(2 ** -.5),\n",
    "#     uv_averaging_range=1e-4,\n",
    "    depth_averaging_range=1e-5,\n",
    ").squeeze(0)\n",
    "\n",
    "render = render.where(render.isfinite(), render.new_zeros([]))\n",
    "img = render.permute(1, 2, 0).mul(255).clamp(0, 255).byte()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a45bdf",
   "metadata": {},
   "source": [
    "Compare the photo from the right camera with the rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3605b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.numpy()).save('/tmp/render.png')\n",
    "Image.fromarray(texture_right).save('/tmp/texture.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
